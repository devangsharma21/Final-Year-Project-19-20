{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87916544/87910968 [==============================] - 4s 0us/step\n"
     ]
    }
   ],
   "source": [
    "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), # Shape of our images\n",
    "                                include_top = False, # Leave out the last fully connected layer\n",
    "                                weights = 'imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in pre_trained_model.layers:\n",
    "  layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('acc')>0.959):\n",
    "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
    "      self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import layers\n",
    "from keras import Model\n",
    "\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(pre_trained_model.output)\n",
    "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "# Add a dropout rate of 0.2\n",
    "x = layers.Dropout(0.2)(x)                  \n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense  (1, activation='sigmoid')(x)           \n",
    "\n",
    "model = Model( pre_trained_model.input, x) \n",
    "\n",
    "model.compile(optimizer = RMSprop(lr=0.0001), \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 105 images belonging to 2 classes.\n",
      "Found 26 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
    "                                   rotation_range = 40,\n",
    "                                   width_shift_range = 0.2,\n",
    "                                   height_shift_range = 0.2,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('/floyd/input/umich/training',\n",
    "                                                 target_size = (150, 150),\n",
    "                                                 batch_size = 16,\n",
    "                                                 class_mode = 'binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('/floyd/input/umich/validation',\n",
    "                                            target_size = (150, 150),\n",
    "                                            batch_size = 16,\n",
    "                                            class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "105/105 [==============================] - 265s 3s/step - loss: 0.7753 - acc: 0.7567 - val_loss: 0.5252 - val_acc: 0.7692\n",
      "Epoch 2/30\n",
      "105/105 [==============================] - 258s 2s/step - loss: 0.5105 - acc: 0.8101 - val_loss: 0.6223 - val_acc: 0.7692\n",
      "Epoch 3/30\n",
      "105/105 [==============================] - 258s 2s/step - loss: 0.4280 - acc: 0.8513 - val_loss: 0.5348 - val_acc: 0.7692\n",
      "Epoch 4/30\n",
      "105/105 [==============================] - 257s 2s/step - loss: 0.4526 - acc: 0.8423 - val_loss: 0.5570 - val_acc: 0.7692\n",
      "Epoch 5/30\n",
      "105/105 [==============================] - 256s 2s/step - loss: 0.3967 - acc: 0.8570 - val_loss: 0.7605 - val_acc: 0.7692\n",
      "Epoch 6/30\n",
      "105/105 [==============================] - 256s 2s/step - loss: 0.4372 - acc: 0.8543 - val_loss: 0.6547 - val_acc: 0.7692\n",
      "Epoch 7/30\n",
      "105/105 [==============================] - 257s 2s/step - loss: 0.3864 - acc: 0.8744 - val_loss: 0.6640 - val_acc: 0.7692\n",
      "Epoch 8/30\n",
      "105/105 [==============================] - 257s 2s/step - loss: 0.4434 - acc: 0.8460 - val_loss: 0.6002 - val_acc: 0.7692\n",
      "Epoch 9/30\n",
      "105/105 [==============================] - 255s 2s/step - loss: 0.4153 - acc: 0.8643 - val_loss: 0.7035 - val_acc: 0.7692\n",
      "Epoch 10/30\n",
      "105/105 [==============================] - 254s 2s/step - loss: 0.3496 - acc: 0.8808 - val_loss: 0.6962 - val_acc: 0.7692\n",
      "Epoch 11/30\n",
      "105/105 [==============================] - 254s 2s/step - loss: 0.3824 - acc: 0.8780 - val_loss: 0.6517 - val_acc: 0.7692\n",
      "Epoch 12/30\n",
      "105/105 [==============================] - 254s 2s/step - loss: 0.3705 - acc: 0.8749 - val_loss: 0.7028 - val_acc: 0.7692\n",
      "Epoch 13/30\n",
      "105/105 [==============================] - 255s 2s/step - loss: 0.4043 - acc: 0.8789 - val_loss: 0.8008 - val_acc: 0.7692\n",
      "Epoch 14/30\n",
      "105/105 [==============================] - 254s 2s/step - loss: 0.3599 - acc: 0.8832 - val_loss: 0.6309 - val_acc: 0.7692\n",
      "Epoch 15/30\n",
      "105/105 [==============================] - 254s 2s/step - loss: 0.3427 - acc: 0.8871 - val_loss: 0.6548 - val_acc: 0.7692\n",
      "Epoch 16/30\n",
      "105/105 [==============================] - 255s 2s/step - loss: 0.3745 - acc: 0.8580 - val_loss: 0.7352 - val_acc: 0.7692\n",
      "Epoch 17/30\n",
      "105/105 [==============================] - 256s 2s/step - loss: 0.3791 - acc: 0.8743 - val_loss: 0.6529 - val_acc: 0.7692\n",
      "Epoch 18/30\n",
      "105/105 [==============================] - 256s 2s/step - loss: 0.3502 - acc: 0.8825 - val_loss: 0.6892 - val_acc: 0.7692\n",
      "Epoch 19/30\n",
      "105/105 [==============================] - 256s 2s/step - loss: 0.3091 - acc: 0.8977 - val_loss: 0.6905 - val_acc: 0.7692\n",
      "Epoch 20/30\n",
      "105/105 [==============================] - 256s 2s/step - loss: 0.3767 - acc: 0.8823 - val_loss: 0.6369 - val_acc: 0.7692\n",
      "Epoch 21/30\n",
      "105/105 [==============================] - 256s 2s/step - loss: 0.2999 - acc: 0.8955 - val_loss: 0.8109 - val_acc: 0.7692\n",
      "Epoch 22/30\n",
      "105/105 [==============================] - 256s 2s/step - loss: 0.3304 - acc: 0.8855 - val_loss: 0.8094 - val_acc: 0.7692\n",
      "Epoch 23/30\n",
      "105/105 [==============================] - 256s 2s/step - loss: 0.3162 - acc: 0.8863 - val_loss: 0.7672 - val_acc: 0.7692\n",
      "Epoch 24/30\n",
      "105/105 [==============================] - 256s 2s/step - loss: 0.3962 - acc: 0.8728 - val_loss: 0.7048 - val_acc: 0.7692\n",
      "Epoch 25/30\n",
      "105/105 [==============================] - 256s 2s/step - loss: 0.2983 - acc: 0.8990 - val_loss: 0.7733 - val_acc: 0.7692\n",
      "Epoch 26/30\n",
      "105/105 [==============================] - 256s 2s/step - loss: 0.2942 - acc: 0.8986 - val_loss: 0.8370 - val_acc: 0.7692\n",
      "Epoch 27/30\n",
      "105/105 [==============================] - 257s 2s/step - loss: 0.2885 - acc: 0.9000 - val_loss: 0.8667 - val_acc: 0.7692\n",
      "Epoch 28/30\n",
      "105/105 [==============================] - 256s 2s/step - loss: 0.3286 - acc: 0.8942 - val_loss: 0.7388 - val_acc: 0.7692\n",
      "Epoch 29/30\n",
      "105/105 [==============================] - 256s 2s/step - loss: 0.3273 - acc: 0.8835 - val_loss: 0.8164 - val_acc: 0.7692\n",
      "Epoch 30/30\n",
      "105/105 [==============================] - 255s 2s/step - loss: 0.2676 - acc: 0.9113 - val_loss: 0.7615 - val_acc: 0.7692\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f99cfe48240>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = myCallback()\n",
    "model.fit_generator(training_set,\n",
    "                         steps_per_epoch = 105,\n",
    "                         epochs = 30,\n",
    "                         validation_data = test_set,\n",
    "                         validation_steps = 26,\n",
    "                         callbacks = [callbacks])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('inception_heart_sounds.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('inception_heart_sounds.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00056984]]\n",
      "Murmur\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "tc = {0:'Murmur', 1: 'Normal'}\n",
    "\n",
    "test_image = image.load_img('/floyd/input/umich/training/Murmur/17.png', target_size = (150, 150))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "\n",
    "result  = model.predict(test_image)\n",
    "print(result)\n",
    "res=1\n",
    "if result<0.5:\n",
    "    res=0\n",
    "# res = np.argmax(result)\n",
    "print(tc[res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
