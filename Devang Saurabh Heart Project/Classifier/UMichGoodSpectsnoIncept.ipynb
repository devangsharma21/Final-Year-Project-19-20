{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc = {0:'Murmur', 1: 'Normal'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "    \n",
    "model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape= (64, 64, 3)))\n",
    "    \n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "   \n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    " \n",
    "model.add(Flatten())\n",
    "    \n",
    "model.add(Dense(units = 128, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "    \n",
    "model.add(Dense(units = 1, activation='sigmoid'))\n",
    "     \n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 84 images belonging to 2 classes.\n",
      "Found 19 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('/floyd/input/upgradespects/Training',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 16,\n",
    "                                                 class_mode = 'binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('/floyd/input/upgradespects/Validation',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 16,\n",
    "                                            class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "84/84 [==============================] - 43s 515ms/step - loss: 0.4989 - acc: 0.7635 - val_loss: 0.2088 - val_acc: 0.8449\n",
      "Epoch 2/30\n",
      "84/84 [==============================] - 40s 482ms/step - loss: 0.2458 - acc: 0.8959 - val_loss: 0.0249 - val_acc: 1.0000\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 40s 477ms/step - loss: 0.0916 - acc: 0.9747 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 40s 475ms/step - loss: 0.0859 - acc: 0.9717 - val_loss: 0.0761 - val_acc: 0.9465\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 41s 485ms/step - loss: 0.0282 - acc: 0.9933 - val_loss: 1.6108e-04 - val_acc: 1.0000\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 40s 480ms/step - loss: 0.0355 - acc: 0.9889 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 41s 484ms/step - loss: 0.0416 - acc: 0.9873 - val_loss: 1.1690e-04 - val_acc: 1.0000\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 41s 490ms/step - loss: 0.0460 - acc: 0.9858 - val_loss: 6.2958e-04 - val_acc: 1.0000\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 41s 486ms/step - loss: 0.0213 - acc: 0.9955 - val_loss: 2.9585e-05 - val_acc: 1.0000\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 40s 479ms/step - loss: 0.0090 - acc: 0.9970 - val_loss: 1.9773e-05 - val_acc: 1.0000\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 41s 484ms/step - loss: 0.0070 - acc: 0.9993 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 41s 488ms/step - loss: 0.0039 - acc: 0.9993 - val_loss: 5.9251e-05 - val_acc: 1.0000\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 40s 479ms/step - loss: 0.0920 - acc: 0.9725 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 41s 483ms/step - loss: 0.0675 - acc: 0.9755 - val_loss: 0.0050 - val_acc: 1.0000\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 40s 476ms/step - loss: 0.0148 - acc: 0.9963 - val_loss: 1.4069e-04 - val_acc: 1.0000\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 41s 485ms/step - loss: 0.0056 - acc: 0.9985 - val_loss: 3.9436e-06 - val_acc: 1.0000\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 40s 479ms/step - loss: 0.0054 - acc: 0.9985 - val_loss: 1.5626e-06 - val_acc: 1.0000\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 40s 478ms/step - loss: 0.0023 - acc: 0.9993 - val_loss: 2.9475e-06 - val_acc: 1.0000\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 40s 471ms/step - loss: 3.4120e-04 - acc: 1.0000 - val_loss: 1.3516e-06 - val_acc: 1.0000\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 39s 470ms/step - loss: 4.9384e-04 - acc: 1.0000 - val_loss: 2.6842e-06 - val_acc: 1.0000\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 42s 495ms/step - loss: 0.0227 - acc: 0.9911 - val_loss: 3.1397e-06 - val_acc: 1.0000\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 40s 481ms/step - loss: 0.0051 - acc: 0.9978 - val_loss: 2.3955e-06 - val_acc: 1.0000\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 40s 474ms/step - loss: 0.0152 - acc: 0.9948 - val_loss: 3.5881e-04 - val_acc: 1.0000\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 40s 473ms/step - loss: 0.0023 - acc: 0.9993 - val_loss: 5.9816e-04 - val_acc: 1.0000\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 40s 478ms/step - loss: 6.8953e-04 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 40s 480ms/step - loss: 7.2349e-04 - acc: 1.0000 - val_loss: 3.7427e-06 - val_acc: 1.0000\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 40s 472ms/step - loss: 4.2322e-04 - acc: 1.0000 - val_loss: 4.5571e-06 - val_acc: 1.0000\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 41s 484ms/step - loss: 6.4825e-04 - acc: 1.0000 - val_loss: 9.0570e-06 - val_acc: 1.0000\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 41s 483ms/step - loss: 7.7133e-05 - acc: 1.0000 - val_loss: 7.6303e-06 - val_acc: 1.0000\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 40s 481ms/step - loss: 6.9982e-05 - acc: 1.0000 - val_loss: 3.0986e-06 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd07e043630>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(training_set,\n",
    "                         steps_per_epoch = 84,\n",
    "                         epochs = 30,\n",
    "                         validation_data = test_set,\n",
    "                         validation_steps = 19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('UMichGoodSpects.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "# model = load_model('inception_heart_sounds.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]]\n",
      "Normal\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "test_image = image.load_img('/floyd/input/upgradespects/Validation/Normal/9.png', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "\n",
    "result  = model.predict(test_image)\n",
    "print(result)\n",
    "res=1\n",
    "if result<0.5:\n",
    "    res=0\n",
    "# res = np.argmax(result)\n",
    "print(tc[res])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
